---
title: "Drosophila notebook"
output: html_notebook
---



 notes - think of this as a lab notebook for your analysis, write notes, thoughts and process here, run code in chunks


### Experiment 1 

```{r}
performance::check_model(eggcountingls1)
performance::check_model(eggcountingls1, check = c("qq"))
```
Normality: looks awful
linearity/ homogenity: pretty awful too 

So! 

GLM? 
QUESTION!!!!
I am beginning to see through going through different analysis that you cannot have one without the other with regards to good normality and linearity/ homogenity
So what is preffered: good normality or good linearity/ homogenity? go with glm..? 


eggcountinglsglm <- glm(egg_numbers ~ diet, data = long_egg_counting1, family = quasipoisson)
summary(eggcountinglsglm)

```{r}
performance::check_model(eggcountinglsglm)
performance::check_model(eggcountinglsglm, check = c("qq"))
```
normality : lines are not really on the line 
linerity/homogenity: points arent as close together but the line is not flat? 


Seeing if there are big differences in the summary() function results 

```{r}
summary(eggcountingls1)
summary(eggcountinglsglm)
```

QUESTION!!!
how to compare values? 
glm results are in log so..? 

log(54.50)the same
log(15.30) = 2.72 = 0.2474 - very much not the same, why? 

exp(3.99)
more or less the same?? 

cannot do this for "-" 
also how do i transform log values back? 
I remember from the workbook (and looking at the new one again), that it was 
exp? 
The first values calculated are the same, so choose models based on performance? 


Feeding behaviour analysis: 

Using LM: 
```{r}
performance::check_model(exp1alllm)
performance::check_model(exp1alllm, check = c("qq"))
```
normality: points are too close together 
linerity/homogenity:  gets bad at the end 

Using GLM - day IS just significant, but with quasi: 
```{r}
performance::check_model(exp1allglm2)
performance::check_model(exp1allglm2, check = c("qq"))
```
normality : looks awful 
linerity/homogenity:  looks quite ok 


lm looks better... 
```{r}
summary(exp1alllm)
```


### Experiment 2 




### Experiment 3 


Testing the summary function to look at a poisson glm test 
```{r}
summary(exp3allglm1)
```


QUESTION!!: 

If I have a model which is poisson
Do I 
still use drop1 and let it be quasi-poisson 
or 
just use summary to see if a variable is significant? 



Checking performance for both of the models 
```{r}
performance::check_model(exp3alllm2)
```

```{r}
performance::check_model(exp3alllm2, check=c("qq"))
```

```{r}
performance::check_model(exp3allglm2)
```

```{r}
performance::check_model(exp3allglm2, check=c("qq"))
```

Th performance check for the linear model shows the homogenity of variance points to be very close together 
The performance check for the generalised linear model shows the homogenity of variance points to be further apart. 
Hence, for the homogenity of variance; the generalized linear model is better to follow. 

For the normality of residuals for the linear model isn't great. Especially at -2, to -2 points. 
The normality of residuals for the generalized linear model doesn't differ much from that of the linear model. 

The performance shows none of the models are great, but the generalized linear model is slighlty better, and also complex? 
I could go into using more complex models but it is best to stop here as there is very little difference between the ones that have been tried. 

Final choice: generalised linear model with quasipoisson (and with day dropped from the model).
Now have chosen generalised linear model. 

QUESTION!! 
Experiment 3 
Write up 
What is the small number on the F value?? 

Offspring counting for experiment 3 
Data Analysis 

1. original fly numbers 

a. model of just alone plate 

linear model
```{r}
performance::check_model(exp3offspring_alone_lm, check = c("qq"))
performance::check_model(exp3offspring_alone_lm)
```
- linearity : points are too close together 
- homogenity of variance: points are too close together 
- normality of residuals look okay



b. model of just both plate
```{r}
performance::check_model(exp3offspring_both_lm)
performance::check_model(exp3offspring_both_lm, check = c("qq"))
```
- linearity: points are mostly too close together 
- homogenity: points too close 
- normal distribution: looks good 



c. model of alone and both plate with an interaction effect 
```{r}
performance::check_model(exp3offspringall)
performance::check_model(exp3offspringall, check = c("qq"))
```
- not too bad 
- linearity points are quite close together 
- homogenity of variance quite close together 
- normal distribution is okay but gets worse at beginning and end 

2. fly proportion numbers 

a. model of just alone plate 
```{r}
performance::check_model(exp3offspring_alone_lm2, check = c("qq"))
performance::check_model(exp3offspring_alone_lm2)
```
- points are much too close together for both
- normality is okay, just worse at the end 

b. model of just both plate
```{r}
performance::check_model(exp3offspring_both_lm2, check = c("qq"))
performance::check_model(exp3offspring_both_lm2)
```
- too close for both 
- normality is okay



c. model of alone and both plate with an interaction effect 
```{r}
performance::check_model(exp3allglm2, check = c("qq"))
performance::check_model(exp3allglm2)
```
- Normality of residuals: not great at all 
- Homogenity of variance: looks decent 


For feeding behaviour analysis for experiment 3: 
- after testing proportional and real values: realising there was not much difference 
- stuck with real values 
- used lm and glms
- found with the glm that quasi-poisson would need to be used and to drop day as is not significant




Experiment 3 - 
OFFSPRING DATA ANALYSIS -- 

Real numbers, offspring alone 
```{r}
performance::check_model(exp3offspring_alone_lm, check = c("qq"))
performance::check_model(exp3offspring_alone_lm)
```
Normality: looks pretty good 
linearity/ homogenity: points are pretty close together 

Real numbers, offspring (females on a plate with males)
```{r}
performance::check_model(exp3offspring_both_lm, check = c("qq"))
performance::check_model(exp3offspring_both_lm)
```
Normality: pretty good, a few alone points 
linearity/ homogenity: points a bit too close together 

Real numbers, both and alone with interaction effect offspring
```{r}
performance::check_model(exp3offspringall, check = c("qq"))
performance::check_model(exp3offspringall)
```
Normality: could be better, but looks okay
linearity/ homogenity: points pretty close together 

proportional numbers, alone 
```{r}
performance::check_model(exp3offspring_alone_lm2 , check = c("qq"))
performance::check_model(exp3offspring_alone_lm2 )
```
Normality: looks okay, few spare points
linearity/ homogenity: points are quite close together 

proportional numbers, both
```{r}
performance::check_model(exp3offspring_both_lm2 , check = c("qq"))
performance::check_model(exp3offspring_both_lm2 )
```
Normality: looks okay, few spare points
linearity/ homogenity: points are quite close together 

proportional numbers, both and alone including an interaction effect 
```{r}
performance::check_model(exp3offspring_lm3,check = c("qq"))
performance::check_model(exp3offspring_lm3)
```
Normality: doesn't look great, few loose points 
linearity/ homogenity: points are too close together 


QUESTION!!
We discussed that for behavioural/feeding count, we found that it doesn't matter about doing proportions. data much less complex 
Does this apply here too? 


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

