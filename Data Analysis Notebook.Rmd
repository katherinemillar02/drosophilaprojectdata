---
title: "Drosophila notebook"
output: html_notebook
---



notes - think of this as a lab notebook for your analysis, write notes, thoughts and process here, run code in chunks


### Experiment 1 -------------------------------------

```{r}
performance::check_model(eggcountingls1)
performance::check_model(eggcountingls1, check = c("qq"))
```
Normality: looks awful
linearity/ homogenity: pretty awful too 

So!
GLM? 
******QUESTION!!!!*****
I am beginning to see through going through different analysis that you cannot have one without the other with regards to good normality and linearity/ homogenity
So what is prefer: good normality or good linearity/ homogenity? go with glm..? 


```{r}
performance::check_model(eggcountinglsglm)
performance::check_model(eggcountinglsglm, check = c("qq"))
summary(eggcountinglsglm)
```



```{r}
performance::check_model(eggcountinglsglm)
performance::check_model(eggcountinglsglm, check = c("qq"))
```
normality : lines are not really on the line 
linerity/homogenity: points aren't as close together but the line is not flat? 


Seeing if there are big differences in the summary() function results 
why are the log values different when transferred to non log 
glm vs lm -- is that why we do different? 

```{r}
summary(eggcountingls1)
summary(eggcountinglsglm)
```

******QUESTION!!!!*****
how to compare values? 
glm results are in log so..? 
log(54.50)the same
log(15.30) = 2.72 = 0.2474 - very much not the same, why? 
exp(3.99)
more or less the same?? 
cannot do this for "-" 
also how do i transform log values back? 
I remember from the workbook (and looking at the new one again), that it was 
exp? 
The first values calculated are the same, so choose models based on performance? 


Feeding behaviour analysis: 

Using LM: 
```{r}
performance::check_model(exp1alllm)
performance::check_model(exp1alllm, check = c("qq"))
```
normality: points are too close together 
linerity/homogenity:  gets bad at the end 

Using GLM - day IS just significant, but with quasi: 
day stats 
```{r}
drop1(exp1allglm2, test = "F")

emmeans::emmeans(exp1allglm2, specs = pairwise ~ sex + diet)
emmeans::emmeans(exp1alllm, specs = pairwise ~ sex + diet + diet * sex ) 
emmeans::emmeans(exp1alllm, specs = pairwise ~ sex + diet) 

exp1allglm2 %>% broom::tidy(conf.int = T) %>% 
 select(-`std.error`) %>% 
mutate_if(is.numeric, round, 2) %>% 
kbl(col.names = c("Predictors",
                    "Estimates",
                    "Z-value",
                    "P",
                    "Lower 95% CI",
                    "Upper 95% CI"),
      caption = "Linear model coefficients", 
    booktabs = T) %>% 
   kable_styling(full_width = FALSE, font_size=16)


broom::tidy(exp1alllm, conf.int=T, conf.level=0.95)


summary(exp1alllm)
anova(exp1alllm)

```

do a post-hoc analysis?? 




2~903 

```{r}
anova(exp2bglm2)
anova(exp2als2a)


```



```{r}
performance::check_model(exp1allglm2)
performance::check_model(exp1allglm2, check = c("qq"))
```
normality : looks awful 
linerity/homogenity:  looks quite ok 


lm looks better... 
```{r}
summary(exp1alllm)
broom::tidy(exp1alllm)
anova(exp1alllm)
```

what it shows 
not much sig diff between 1:2 female and 1:8 male 

big sig diff between 1:2 female and 2:1 male - big diff in low protein and low carb? 
< p = 0.001 

probaly use emmeans package to compare properly? 






### Experiment 2a ---------------------

DATA ANALYSIS 
What there is to be analysed 

- egg count 

visualising the data for egg count
```{r}
mated_females_e2_eggcount_plot + virgin_female_e2_eggcount_plot
```

linear model
```{r}
exp2a_egg_lm <- lm(egg_numbers ~ diet * type, data = exp2a_all_egg)

performance::check_model(exp2a_egg_lm)
performance::check_model(exp2a_egg_lm, check = c("qq"))

summary(exp2a_egg_lm)
```

generalised linear model 
```{r}
exp2a_egg_glm <- glm(egg_numbers ~ diet * type, data = exp2a_all_egg, family = poisson)

performance::check_model(exp2a_egg_glm)
performance::check_model(exp2a_egg_lm, check = c("qq"))
```


linear model probably looks better 

### Experiment 2b ---------------------

trying with glm with day dropped as not significant and with quasi-poisson for overdisperson
```{r}
performance::check_model(exp2bglm2)
performance::check_model(exp2bglm2, check = c("qq"))
```
normality: doesnt look great, points are okay in the middle 
homogenity: looks pretty good 

trying with lm... with day dropped as not significant 
```{r}
performance::check_model(exp2blm2)
performance::check_model(exp2blm2, check = c("qq"))
```
normality: points only okay in the middle 
homogenity/ linearity: points very close together but line is flat 


from this... glm is better option!!

seeing if summary matches for the sake of it
```{r}
summary(exp2bglm2)
summary(exp2blm2)
```

exp(0.3800)
- numbers seem very different even when put back to normal... bit weird? 


offspring counts 

```{r}
summary(exp2boffspringlm)
broom::tidy(exp2boffspringlm)
emmeans::emmeans(exp2boffspringlm, specs = pairwise ~ diet)
offspring_ex2b_plot

performance::check_model(exp2boffspringlm, check = c("qq"))
performance::check_model(exp2boffspringlm)


```

******QUESTION!!!!*****

says 1:8 + 1:2 are significant but in a pairwise they are not at all? 


1:8 significantly higher than 1:2 but not a lot to it 

```{r}
summary(exp2boffspringglm)
broom::tidy(exp2boffspringlm)

588/486.31

performance::check_model(exp2boffspringglm, check = c("qq"))
performance::check_model(exp2boffspringglm)

```

p=0.019

overdispersion so use quasi !! 

there's not a lot of difference so use glm? 


### Experiment 3 --------------------------

# Feeding behaviour data analysis -----------------

Testing the summary function to look at a poisson glm test 
```{r}
summary(exp3allglm1)
```


******QUESTION!!!!*****

If I have a model which is poisson
Do I 
still use drop1 and let it be quasi-poisson 
or 
just use summary to see if a variable is significant? 



Checking performance for both of the models 
```{r}
performance::check_model(exp3alllm2)
performance::check_model(exp3alllm2, check=c("qq"))
```

```{r}
performance::check_model(exp3alllm2, check=c("qq"))
```

```{r}
performance::check_model(exp3allglm2)
```

```{r}
performance::check_model(exp3allglm2, check=c("qq"))
performance::check_model(exp3allglm2)
```

Th performance check for the linear model shows the homogenity of variance points to be very close together 
The performance check for the generalised linear model shows the homogenity of variance points to be further apart. 
Hence, for the homogenity of variance; the generalized linear model is better to follow. 

For the normality of residuals for the linear model isn't great. Especially at -2, to -2 points. 
The normality of residuals for the generalized linear model doesn't differ much from that of the linear model. 

The performance shows none of the models are great, but the generalized linear model is slighlty better, and also complex? 
I could go into using more complex models but it is best to stop here as there is very little difference between the ones that have been tried. 

Final choice: generalised linear model with quasipoisson (and with day dropped from the model).
Now have chosen generalised linear model. 











******QUESTION!!!!*****
Experiment 3 
Write up -- 
What is the small number on the F value?? 

e.g. from the write up drosophila in the workbook 

F2,118 = 0.512

f 
2 = df?
118 = lower confidence interval?
0.512 = the f value 

1
0.91
0.94

```{r}
summary(exp3allglm)
broom::tidy(exp3allglm)
emmeans::emmeans(exp3allglm, specs = pairwise ~ diet + status + day)
drop1(exp3allglm, test = "F")
```


```{r}
performance::check
```





Offspring counting for experiment 3 
Data Analysis 

1. original fly numbers 

a. model of just alone plate 

linear model
```{r}
performance::check_model(exp3offspring_alone_lm, check = c("qq"))
performance::check_model(exp3offspring_alone_lm)
```
- linearity : points are too close together 
- homogenity of variance: points are too close together 
- normality of residuals look okay

```{r}
performance::check_model(exp3allglm2, check = c("qq"))
performance::check_model(exp3allglm2)
```


b. model of just both plate
```{r}
performance::check_model(exp3offspring_both_lm)
performance::check_model(exp3offspring_both_lm, check = c("qq"))
```
- linearity: points are mostly too close together 
- homogenity: points too close 
- normal distribution: looks good 



c. model of alone and both plate with an interaction effect 
```{r}
performance::check_model(exp3offspringall)
performance::check_model(exp3offspringall, check = c("qq"))
```
- not too bad 
- linearity points are quite close together 
- homogenity of variance quite close together 
- normal distribution is okay but gets worse at beginning and end 

2. fly proportion numbers 

a. model of just alone plate 
```{r}
performance::check_model(exp3offspring_alone_lm2, check = c("qq"))
performance::check_model(exp3offspring_alone_lm2)
```
- points are much too close together for both
- normality is okay, just worse at the end 

b. model of just both plate
```{r}
performance::check_model(exp3offspring_both_lm2, check = c("qq"))
performance::check_model(exp3offspring_both_lm2)
```
- too close for both 
- normality is okay



c. model of alone and both plate with an interaction effect 
```{r}
performance::check_model(exp3allglm2, check = c("qq"))
performance::check_model(exp3allglm2)
```
- Normality of residuals: not great at all 
- Homogenity of variance: looks decent 


For feeding behaviour analysis for experiment 3: 
- after testing proportional and real values: realising there was not much difference 
- stuck with real values 
- used lm and glms
- found with the glm that quasi-poisson would need to be used and to drop day as is not significant



# Offspring data analysis -------------------- 

Real numbers, offspring alone 
```{r}
performance::check_model(exp3offspring_alone_lm, check = c("qq"))
performance::check_model(exp3offspring_alone_lm)
```
Normality: looks pretty good 
linearity/ homogenity: points are pretty close together 

Real numbers, offspring (females on a plate with males)
```{r}
performance::check_model(exp3offspring_both_lm, check = c("qq"))
performance::check_model(exp3offspring_both_lm)
```
Normality: pretty good, a few alone points 
linearity/ homogenity: points a bit too close together 

Real numbers, both and alone with interaction effect offspring
```{r}
performance::check_model(exp3offspringall, check = c("qq"))
performance::check_model(exp3offspringall)
```
Normality: could be better, but looks okay
linearity/ homogenity: points pretty close together 

proportional numbers, alone 
```{r}
performance::check_model(exp3offspring_alone_lm2 , check = c("qq"))
performance::check_model(exp3offspring_alone_lm2 )
```
Normality: looks okay, few spare points
linearity/ homogenity: points are quite close together 

proportional numbers, both
```{r}
performance::check_model(exp3offspring_both_lm2 , check = c("qq"))
performance::check_model(exp3offspring_both_lm2 )
```
Normality: looks okay, few spare points
linearity/ homogenity: points are quite close together 

proportional numbers, both and alone including an interaction effect 
```{r}
performance::check_model(exp3offspring_lm3,check = c("qq"))
performance::check_model(exp3offspring_lm3)

summary(exp3offspring_lm3)
```
Normality: doesn't look great, few loose points 
linearity/ homogenity: points are too close together 


******QUESTION!!!!*****
We discussed that for behavioural/feeding count, we found that it doesn't matter about doing proportions. data much less complex 
Does this apply here too? 

what offsprping model is best
lets say proportions do not matter 
glm or lm? 

...data visualisations...

```{r}
offspring_both_exp3_plot + offspring_alone_exp3_plot
```


```{r}
offspring_both_exp3_plot2 + offspring_alone_exp3_plot2
```

probs go with normal values!!


data analysis !!
```{r}
performance::check_model(exp3offspringall)
performance::check_model(exp3offspringall, check = c("qq"))

performance::check_model(exp3offspringallglm2)
performance::check_model(exp3offspringallglm2, check = c("qq"))
```

```{r}
summary(exp3offspringall)
```

all round linear model looks better!!




